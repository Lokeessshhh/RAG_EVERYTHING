# RAG Everything

A production-ready, full-stack **Retrieval-Augmented Generation (RAG)** chatbot that lets you embed and chat with virtually any type of content â€” PDFs, code, YouTube videos, websites, images, audio, GitHub repos, and AI chat exports.

---

## âœ¨ Features

- ğŸ§  **Smart Context Resolution** â€” resolves pronouns like "it", "that", "this" from conversation history before searching
- ğŸ’¬ **Conversation Memory** â€” tracks last 6 messages so follow-up questions work naturally
- ğŸ” **Semantic Search + Reranking** â€” vector search (top-50) â†’ Voyage AI rerank (top-10) â†’ LLM answer
- ğŸ“š **11 Source Types** â€” ingest anything, ask anything
- ğŸŒ **Multilingual** â€” English, Hindi, and Hinglish support
- âš¡ **Streaming Responses** â€” real-time token-by-token streaming
- ğŸ—ƒï¸ **Library Management** â€” view, search, and delete ingested sources
- ğŸ“ **Embed from Chat** â€” paperclip button lets you embed content directly from the chat page
- ğŸŒ™ **Dark / Light Mode** â€” theme toggle built in
- ğŸ™ï¸ **Voice Input** â€” speak your queries

---

## ğŸ—‚ï¸ Supported Source Types

| Type | What it ingests |
|---|---|
| **File Upload** | PDF, TXT, MD, CSV, Python, JS, TS, Java, Go, C/C++, and more |
| **GitHub Repo** | Any public repository (code + docs) |
| **YouTube** | Video transcripts (Hindi, English, any language) |
| **Website** | Crawls pages via sitemap + Crawl4AI |
| **Image** | Gemini 1.5 Flash vision analysis + pytesseract OCR |
| **Audio / Voice** | Transcribed via Google Web Speech API |
| **Paste Text** | Direct text input with a source name |
| **AI Chat** | ChatGPT, Claude, Gemini, Grok, Perplexity shared links |

---

## ğŸ—ï¸ Architecture

```
User Query
    â”‚
    â–¼
LLM resolves context (last 6 messages) â†’ final search query
    â”‚
    â–¼
Jina Embeddings (1024-dim) â†’ Zilliz Vector DB search (top-50)
    â”‚
    â–¼
Voyage AI Rerank (top-10) â†’ LLM (Cloudflare Llama 8B) â†’ Streaming response
```

---

## ğŸ› ï¸ Tech Stack

### Backend
| Layer | Technology |
|---|---|
| Framework | FastAPI (Python) |
| Embeddings | Jina AI v5-text-small (1024-dim) |
| Vector DB | Zilliz Cloud (Milvus) |
| LLM | Cloudflare Workers (Llama 8B) |
| Reranking | Voyage AI rerank-2 |
| AI Parsing | Groq Llama 4 Scout 17B |
| Image Analysis | Google Gemini 1.5 Flash |
| Web Crawling | Crawl4AI |
| Caching | Upstash Redis |
| Deployment | Render |

### Frontend
| Layer | Technology |
|---|---|
| Framework | React + TypeScript |
| Build Tool | Vite |
| Styling | Tailwind CSS |
| Animations | Framer Motion |
| Icons | Lucide React |
| Deployment | Vercel |

---

## ğŸš€ Quick Start (Local)

### Prerequisites
- Python 3.10+
- Node.js 18+
- All API keys listed in `.env.example`

### 1. Clone the repo
```bash
git clone https://github.com/Lokeessshhh/RAG_EVERYTHING.git
cd RAG_EVERYTHING
```

### 2. Backend setup
```bash
python -m venv .venv
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # Mac/Linux

pip install -r requirements.txt

cp .env.example .env
# Fill in all API keys in .env

uvicorn backend.main:app --reload --port 8000
```

### 3. Frontend setup
```bash
cd frontend
npm install
cp .env.example .env.local
# Set VITE_API_URL=http://localhost:8000/api in .env.local

npm run dev
```

Open [http://localhost:5173](http://localhost:5173)

---

## ğŸ”‘ Environment Variables

Copy `.env.example` to `.env` and fill in the following:

| Variable | Service | Get it at |
|---|---|---|
| `JINA_API_KEY` | Jina AI Embeddings | [jina.ai](https://jina.ai) |
| `GROQ_API_KEY` | Groq (AI Parser) | [console.groq.com](https://console.groq.com/keys) |
| `VOYAGE_API_KEY` | Voyage AI Reranking | [voyageai.com](https://www.voyageai.com) |
| `ZILLIZ_URI` | Zilliz Vector DB | [cloud.zilliz.com](https://cloud.zilliz.com) |
| `ZILLIZ_TOKEN` | Zilliz Vector DB | [cloud.zilliz.com](https://cloud.zilliz.com) |
| `CLOUDFLARE_WORKER_URL` | LLM Inference | Your Cloudflare Worker URL |
| `GEMINI_API_KEY` | Image Analysis | [aistudio.google.com](https://aistudio.google.com/app/apikey) |
| `UPSTASH_REDIS_REST_URL` | Redis Cache | [upstash.com](https://upstash.com) |
| `UPSTASH_REDIS_REST_TOKEN` | Redis Cache | [upstash.com](https://upstash.com) |

**Frontend only (Vercel):**

| Variable | Value |
|---|---|
| `VITE_API_URL` | `https://your-backend.onrender.com/api` |

---

## â˜ï¸ Deployment

### Backend â†’ Render

1. Push repo to GitHub
2. Create a new **Web Service** on [Render](https://render.com)
3. Connect your GitHub repo â€” Render auto-detects `render.yaml`
4. Add all environment variables in the Render dashboard
5. Deploy â€” start command is:
   ```
   uvicorn backend.main:app --host 0.0.0.0 --port $PORT
   ```

### Frontend â†’ Vercel

1. Import your GitHub repo on [Vercel](https://vercel.com)
2. Set **Root Directory** to `frontend`
3. Add environment variable:
   - `VITE_API_URL` = `https://your-backend.onrender.com/api`
4. Deploy â€” Vercel auto-detects Vite via `vercel.json`

---

## ğŸ“¡ API Endpoints

### Ingestion
| Endpoint | Method | Description |
|---|---|---|
| `/api/ingest/upload` | POST | Upload files (PDF, TXT, CSV, code, etc.) |
| `/api/ingest/github` | POST | Ingest a GitHub repo |
| `/api/ingest/youtube` | POST | Ingest YouTube transcript |
| `/api/ingest/website` | POST | Crawl and ingest a website |
| `/api/ingest/image` | POST | Ingest an image |
| `/api/ingest/audio` | POST | Ingest audio/voice file |
| `/api/ingest/text` | POST | Ingest plain text |
| `/api/ingest/ai-chat` | POST | Ingest AI chat share link |

### Chat & Library
| Endpoint | Method | Description |
|---|---|---|
| `/api/chat` | POST | Streaming RAG chat |
| `/api/library` | GET | List all ingested sources |
| `/api/library` | DELETE | Delete a source |
| `/api/stats` | GET | Embedding usage stats |

---

## ğŸ“ Project Structure

```
RAG_EVERYTHING/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py               # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py             # All configuration constants
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ chat.py           # Chat endpoint + RAG pipeline
â”‚   â”‚   â””â”€â”€ ingest.py         # All ingestion endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ embedder.py       # Jina AI embeddings
â”‚   â”‚   â”œâ”€â”€ vector_store.py   # Zilliz/Milvus operations
â”‚   â”‚   â”œâ”€â”€ retriever.py      # Search + rerank logic
â”‚   â”‚   â”œâ”€â”€ llm.py            # Cloudflare LLM wrapper
â”‚   â”‚   â”œâ”€â”€ cache.py          # Redis caching
â”‚   â”‚   â”œâ”€â”€ upstash_redis.py  # Redis client
â”‚   â”‚   â””â”€â”€ rate_limit.py     # IP rate limiting
â”‚   â””â”€â”€ ingestion/
â”‚       â”œâ”€â”€ text.py           # Text ingester
â”‚       â”œâ”€â”€ pdf.py            # PDF ingester
â”‚       â”œâ”€â”€ csv_ingest.py     # CSV ingester
â”‚       â”œâ”€â”€ code.py           # Code ingester
â”‚       â”œâ”€â”€ github_repo.py    # GitHub ingester
â”‚       â”œâ”€â”€ youtube.py        # YouTube ingester
â”‚       â”œâ”€â”€ website.py        # Website crawler
â”‚       â”œâ”€â”€ image.py          # Image ingester
â”‚       â”œâ”€â”€ voice.py          # Audio/voice ingester
â”‚       â”œâ”€â”€ chat_export.py    # Chat export ingester
â”‚       â””â”€â”€ ai_chat_parsers/  # ChatGPT/Claude/Gemini/Grok/Perplexity parsers
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatPage.tsx      # Main chat interface
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadPage.tsx    # Upload/ingest page
â”‚   â”‚   â”‚   â”œâ”€â”€ LibraryPage.tsx   # Source library
â”‚   â”‚   â”‚   â””â”€â”€ LandingPage.tsx   # Landing page
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ IngestModal.tsx   # Embed from chat modal
â”‚   â”‚   â”‚   â”œâ”€â”€ AppShell.tsx      # Layout shell
â”‚   â”‚   â”‚   â””â”€â”€ Toast.tsx         # Notifications
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.ts            # API client
â”‚   â”œâ”€â”€ vercel.json               # Vercel deployment config
â”‚   â””â”€â”€ .env.example              # Frontend env vars
â”œâ”€â”€ render.yaml                   # Render deployment config
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ .env.example                  # All env vars documented
```

---

## ğŸ§© Chunking Strategy

| Source | Chunk Size | Overlap |
|---|---|---|
| Text | 600 chars | 80 |
| PDF | 700 chars | 100 |
| CSV | per row batch | 0 |
| Code | 800 chars | 0 |
| GitHub | 800 chars | 0 |
| YouTube | 200 words | 30 words |
| Website | 800 chars | 100 |
| Image | 800 chars | 100 |
| Voice | 400 chars | 60 |
| AI Chat | 1200 chars | 100 |

---

## ğŸ“„ License

MIT
